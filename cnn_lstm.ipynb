{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download images and annotations to the data directory\n",
    "# !wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip -P ./data_dir/ -P ./data_dir/\n",
    "# !wget http://images.cocodataset.org/zips/train2014.zip -P ./data_dir/\n",
    "# !wget http://images.cocodataset.org/zips/val2014.zip -P ./data_dir/\n",
    "# # extract zipped images and annotations and remove the zip files\n",
    "# !unzip ./data_dir/annotations_trainval2014.zip -d ./data_dir/\n",
    "# !rm ./data_dir/annotations_trainval2014.zip\n",
    "# !unzip ./data_dir/train2014.zip -d ./data_dir/\n",
    "# !rm ./data_dir/train2014.zip\n",
    "# !unzip ./data_dir/val2014.zip -d ./data_dir/\n",
    "# !rm ./data_dir/val2014.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing caption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pycocotools.coco import COCO\n",
    "from collections import Counter, OrderedDict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/silly_ronny/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"data_dir/annotations/captions_train2014.json\"\n",
    "VAL_PATH = \"data_dir/annotations/captions_val2014.json\"\n",
    "TRAIN_IMAGE_PATH = \"data_dir/train2014\"\n",
    "VAL_IMAGE_PATH = \"data_dir/val2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(TRAIN_PATH, 'r') as f:\n",
    "            # annotations = json.load(f)['annotations']\n",
    "            image_map = {img['id']: img['file_name'] for img in json.load(f)['images']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CocoCaptionDataset(Dataset):\n",
    "    def __init__(self, annotation_file, image_dir, transforms=None, tokenizer=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # Load and parse annotations\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            out = json.load(f)\n",
    "        \n",
    "        self.annotations = out['annotations']\n",
    "        self.image_map = {img['id']: img['file_name'] for img in out['images']}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        annotations = self.annotations[index]\n",
    "        caption = annotations['caption']\n",
    "        image_id = annotations['image_id']\n",
    "        image_path = os.path.join(self.image_dir, self.image_map[image_id])\n",
    "        \n",
    "        try:\n",
    "            # Load the image\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Ensure the image is in RGB format\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            # Apply transformations if specified\n",
    "            if self.transforms:\n",
    "                image = self.transforms(image)\n",
    "            \n",
    "            # Tokenize the caption if tokenizer is provided\n",
    "            if self.tokenizer:\n",
    "                caption = self.tokenizer(caption)\n",
    "            \n",
    "            return image, caption\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {image_path}: {e}\")\n",
    "            # Optional: Return a placeholder image and tokenized fallback caption\n",
    "            placeholder_image = Image.new('RGB', (224, 224))  # Example: Blank image\n",
    "            placeholder_caption = \"<UNK>\" if not self.tokenizer else self.tokenizer(\"<UNK>\")\n",
    "            return placeholder_image, placeholder_caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "\n",
    "\n",
    "\n",
    "train_transforms = weights.transforms()\n",
    "val_transforms = weights.transforms()\n",
    "\n",
    "tokenizer = nltk.word_tokenize\n",
    "\n",
    "train_dataset = CocoCaptionDataset(TRAIN_PATH, TRAIN_IMAGE_PATH,\n",
    "                                   transforms=train_transforms, tokenizer=tokenizer)\n",
    "val_dataset = CocoCaptionDataset(VAL_PATH, VAL_IMAGE_PATH,\n",
    "                                   transforms=val_transforms, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import string\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"<unk>\": 0, \"<pad>\": 1}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.n = 2\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.n\n",
    "            self.idx2word[self.n] = word\n",
    "            self.n = self.n+1\n",
    "    \n",
    "    def build_with_sentence(self, sentence, tokenizer, tokenized=False):\n",
    "        if tokenized:\n",
    "            for word in self.process_sentence(sentence):\n",
    "                self.add_word(word)\n",
    "        else:\n",
    "            for word in self.process_sentence(tokenizer(sentence)):\n",
    "                self.add_word(word)\n",
    "            \n",
    "    \n",
    "    def build_vocab(self, list_of_sentences: List[str]):\n",
    "        for sentence in tqdm(list_of_sentences):\n",
    "            self.build_with_sentence(sentence=sentence)\n",
    "            \n",
    "\n",
    "    def process_sentence(self, tokens):\n",
    "        \"\"\"\n",
    "        Normalize tokens by:\n",
    "        - Converting to lowercase\n",
    "        - Removing punctuation\n",
    "        - Stripping whitespace\n",
    "        - Normalizing Unicode characters to their ASCII equivalents\n",
    "        \"\"\"\n",
    "        normalized_tokens = []\n",
    "        for token in tokens:\n",
    "            # Normalize Unicode characters to ASCII\n",
    "            token = unicodedata.normalize('NFKD', token).encode('ascii', 'ignore').decode('utf-8')\n",
    "            # Convert to lowercase\n",
    "            token = token.lower()\n",
    "            # Remove punctuation and strip whitespace\n",
    "            token = token.strip(string.punctuation).strip()\n",
    "            # Add to the result list if not empty\n",
    "            if token:\n",
    "                normalized_tokens.append(token)\n",
    "        return normalized_tokens\n",
    "        \n",
    "    def __getitem__(self, word):\n",
    "        return self.word2idx.get(word, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = Vocab()\n",
    "# for _, caption in tqdm(train_dataset):\n",
    "#     vocab.build_with_sentence(caption, tokenizer=tokenizer, tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202654/202654 [19:50<00:00, 170.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# for _, caption in tqdm(val_dataset):\n",
    "#     vocab.build_with_sentence(caption, tokenizer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(vocab, \"vocab.z\")\n",
    "vocab = joblib.load(\"vocab_v2.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 1,\n",
       " '<pad>': 0,\n",
       " 'a': 2,\n",
       " 'very': 3,\n",
       " 'clean': 4,\n",
       " 'and': 5,\n",
       " 'well': 6,\n",
       " 'decorated': 7,\n",
       " 'empty': 8,\n",
       " 'bathroom': 9,\n",
       " 'panoramic': 10,\n",
       " 'view': 11,\n",
       " 'of': 12,\n",
       " 'kitchen': 13,\n",
       " 'all': 14,\n",
       " 'its': 15,\n",
       " 'appliances': 16,\n",
       " 'blue': 17,\n",
       " 'white': 18,\n",
       " 'with': 19,\n",
       " 'butterfly': 20,\n",
       " 'themed': 21,\n",
       " 'wall': 22,\n",
       " 'tiles': 23,\n",
       " 'photo': 24,\n",
       " 'dining': 25,\n",
       " 'room': 26,\n",
       " 'graffiti-ed': 27,\n",
       " 'stop': 28,\n",
       " 'sign': 29,\n",
       " 'across': 30,\n",
       " 'the': 31,\n",
       " 'street': 32,\n",
       " 'from': 33,\n",
       " 'red': 34,\n",
       " 'car': 35,\n",
       " 'vandalized': 36,\n",
       " 'beetle': 37,\n",
       " 'on': 38,\n",
       " 'road': 39,\n",
       " 'border': 40,\n",
       " 'butterflies': 41,\n",
       " 'paint': 42,\n",
       " 'walls': 43,\n",
       " 'above': 44,\n",
       " 'it': 45,\n",
       " 'an': 46,\n",
       " 'angled': 47,\n",
       " 'beautifully': 48,\n",
       " 'two': 49,\n",
       " 'people': 50,\n",
       " 'are': 51,\n",
       " 'walking': 52,\n",
       " 'down': 53,\n",
       " 'beach': 54,\n",
       " 'sink': 55,\n",
       " 'toilet': 56,\n",
       " 'inside': 57,\n",
       " 'small': 58,\n",
       " 'black': 59,\n",
       " 'square': 60,\n",
       " 'tile': 61,\n",
       " 'floor': 62,\n",
       " 'that': 63,\n",
       " 'needs': 64,\n",
       " 'repairs': 65,\n",
       " 'vanity': 66,\n",
       " 'contains': 67,\n",
       " 'sinks': 68,\n",
       " 'towel': 69,\n",
       " 'for': 70,\n",
       " 'each': 71,\n",
       " 'several': 72,\n",
       " 'metal': 73,\n",
       " 'balls': 74,\n",
       " 'sit': 75,\n",
       " 'in': 76,\n",
       " 'sand': 77,\n",
       " 'near': 78,\n",
       " 'group': 79,\n",
       " 'carrying': 80,\n",
       " 'surf': 81,\n",
       " 'boards': 82,\n",
       " 'brown': 83,\n",
       " 'cabinets': 84,\n",
       " 'backsplash': 85,\n",
       " 'grey': 86,\n",
       " 'counters': 87,\n",
       " 'surfer': 88,\n",
       " 'woman': 89,\n",
       " 'child': 90,\n",
       " 'walk': 91,\n",
       " 'few': 92,\n",
       " 'dim': 93,\n",
       " 'transportation': 94,\n",
       " 'system': 95,\n",
       " 'person': 96,\n",
       " 'protected': 97,\n",
       " 'rain': 98,\n",
       " 'by': 99,\n",
       " 'their': 100,\n",
       " 'umbrella': 101,\n",
       " 'walks': 102,\n",
       " 'has': 103,\n",
       " 'interesting': 104,\n",
       " 'women': 105,\n",
       " 'preparing': 106,\n",
       " 'food': 107,\n",
       " 'one': 108,\n",
       " 'at': 109,\n",
       " 'table': 110,\n",
       " 'home': 111,\n",
       " 'light': 112,\n",
       " 'cat': 113,\n",
       " 'stuck': 114,\n",
       " 'slightly': 115,\n",
       " 'opened': 116,\n",
       " 'window': 117,\n",
       " 'bicycles': 118,\n",
       " 'front': 119,\n",
       " 'shop': 120,\n",
       " 'green': 121,\n",
       " 'tiled': 122,\n",
       " 'highlighted': 123,\n",
       " 'low': 124,\n",
       " 'overhead': 125,\n",
       " 'lighting': 126,\n",
       " 'bicycle': 127,\n",
       " 'is': 128,\n",
       " 'parked': 129,\n",
       " 'bench': 130,\n",
       " 'night': 131,\n",
       " 'horse': 132,\n",
       " 'grazing': 133,\n",
       " 'grass': 134,\n",
       " 'house': 135,\n",
       " 'someone': 136,\n",
       " 'riding': 137,\n",
       " 'bike': 138,\n",
       " 'pedestal': 139,\n",
       " 'located': 140,\n",
       " 'poorly': 141,\n",
       " 'lit': 142,\n",
       " 'this': 143,\n",
       " 'pick-up': 144,\n",
       " 'game': 145,\n",
       " 'shirts': 146,\n",
       " 'skins': 147,\n",
       " 'basketball': 148,\n",
       " 'bathtub': 149,\n",
       " 'shower': 150,\n",
       " 'mirror': 151,\n",
       " 'cabinet': 152,\n",
       " 'countertop': 153,\n",
       " 'includes': 154,\n",
       " 'apple': 155,\n",
       " 'phone': 156,\n",
       " 'teenagers': 157,\n",
       " 'sanded': 158,\n",
       " 'surfboards': 159,\n",
       " 'his': 160,\n",
       " 'to': 161,\n",
       " 'indoor': 162,\n",
       " 'good': 163,\n",
       " 'closeup': 164,\n",
       " 'fire': 165,\n",
       " 'hydrant': 166,\n",
       " 'including': 167,\n",
       " 'chains': 168,\n",
       " 'man': 169,\n",
       " 'standing': 170,\n",
       " 'arms': 171,\n",
       " 'crossed': 172,\n",
       " 'purple': 173,\n",
       " 'bus': 174,\n",
       " 'dressed': 175,\n",
       " 'as': 176,\n",
       " 'nun': 177,\n",
       " 'tall': 178,\n",
       " 'herb': 179,\n",
       " 'toaster': 180,\n",
       " 'oven': 181,\n",
       " 'lady': 182,\n",
       " 'purse': 183,\n",
       " 'along': 184,\n",
       " 'side': 185,\n",
       " 'brightly': 186,\n",
       " 'colored': 187,\n",
       " 'wide': 188,\n",
       " 'angle': 189,\n",
       " 'work': 190,\n",
       " 'area': 191,\n",
       " 'around': 192,\n",
       " 'many': 193,\n",
       " 'silver': 194,\n",
       " 'round': 195,\n",
       " 'ground': 196,\n",
       " 'working': 197,\n",
       " 'counter': 198,\n",
       " 'illuminated': 199,\n",
       " 'sunlight': 200,\n",
       " 'granite': 201,\n",
       " 'countertops': 202,\n",
       " 'skinny': 203,\n",
       " 'field': 204,\n",
       " 'seagulls': 205,\n",
       " 'flying': 206,\n",
       " 'while': 207,\n",
       " 'trucks': 208,\n",
       " 'parking': 209,\n",
       " 'lot': 210,\n",
       " 'no': 211,\n",
       " 'doors': 212,\n",
       " 'dishwasher': 213,\n",
       " 'refrigerator': 214,\n",
       " 'modern': 215,\n",
       " 'glass': 216,\n",
       " 'pieces': 217,\n",
       " 'demonstration': 218,\n",
       " 'maintained': 219,\n",
       " 'hotel': 220,\n",
       " 'making': 221,\n",
       " 'angry': 222,\n",
       " 'face': 223,\n",
       " 'sitting': 224,\n",
       " 'mediocre': 225,\n",
       " 'motel': 226,\n",
       " 'nice': 227,\n",
       " 'hood': 228,\n",
       " 'city': 229,\n",
       " 'sidewalk': 230,\n",
       " 'lined': 231,\n",
       " 'lamp': 232,\n",
       " 'posts': 233,\n",
       " 'tv': 234,\n",
       " 'public': 235,\n",
       " 'restroom': 236,\n",
       " 'been': 237,\n",
       " 'photographed': 238,\n",
       " 'sepia': 239,\n",
       " 'old': 240,\n",
       " 'styled': 241,\n",
       " 'what': 242,\n",
       " 'appears': 243,\n",
       " 'be': 244,\n",
       " 'golden': 245,\n",
       " 'gate': 246,\n",
       " 'bridge': 247,\n",
       " 'peeking': 248,\n",
       " 'out': 249,\n",
       " 'rolled': 250,\n",
       " 'there': 251,\n",
       " 'some': 252,\n",
       " 'pet': 253,\n",
       " 'young': 254,\n",
       " 'boy': 255,\n",
       " 'surfing': 256,\n",
       " 'waves': 257,\n",
       " 'top': 258,\n",
       " 'covered': 259,\n",
       " 'brass': 260,\n",
       " 'pots': 261,\n",
       " 'pans': 262,\n",
       " 'shaving': 263,\n",
       " 'her': 264,\n",
       " 'wooden': 265,\n",
       " 'sky': 266,\n",
       " 'full': 267,\n",
       " 'colorful': 268,\n",
       " 'kites': 269,\n",
       " 'mountain': 270,\n",
       " 'rides': 271,\n",
       " 'river': 272,\n",
       " 'stand': 273,\n",
       " 'lights': 274,\n",
       " 'cupboard': 275,\n",
       " 'raft': 276,\n",
       " 'atop': 277,\n",
       " 'boat': 278,\n",
       " 'water': 279,\n",
       " 'cars': 280,\n",
       " 'trash': 281,\n",
       " 'can': 282,\n",
       " 'garage': 283,\n",
       " 'shorts': 284,\n",
       " 'seat': 285,\n",
       " 'looking': 286,\n",
       " 'jumping': 287,\n",
       " 'onto': 288,\n",
       " 'folded': 289,\n",
       " 'balancing': 290,\n",
       " 'image': 291,\n",
       " 'children': 292,\n",
       " 'paying': 293,\n",
       " 'attention': 294,\n",
       " 'up': 295,\n",
       " 'mill': 296,\n",
       " 'about': 297,\n",
       " 'background': 298,\n",
       " 'compact': 299,\n",
       " 'mounted': 300,\n",
       " 'roof': 301,\n",
       " 'crisp': 302,\n",
       " 'neutral': 303,\n",
       " 'embellished': 304,\n",
       " 'treatments': 305,\n",
       " 'scene': 306,\n",
       " 'stainless': 307,\n",
       " 'steel': 308,\n",
       " 'appliance': 309,\n",
       " 'checkered': 310,\n",
       " 'pattern': 311,\n",
       " 'talking': 312,\n",
       " 'self': 313,\n",
       " 'portrait': 314,\n",
       " 'fancy': 315,\n",
       " 'cell': 316,\n",
       " 'accessories': 317,\n",
       " 'set': 318,\n",
       " 'without': 319,\n",
       " 'snowy': 320,\n",
       " 'skis': 321,\n",
       " 'towels': 322,\n",
       " 'washcloths': 323,\n",
       " 'laid': 324,\n",
       " 'stuffed': 325,\n",
       " 'animal': 326,\n",
       " 'laying': 327,\n",
       " 'bed': 328,\n",
       " 'blacksplash': 329,\n",
       " 'sits': 330,\n",
       " 'open': 331,\n",
       " 'plates': 332,\n",
       " 'vegetables': 333,\n",
       " 'couple': 334,\n",
       " 'toilette': 335,\n",
       " 'computer': 336,\n",
       " 'taking': 337,\n",
       " 'picture': 338,\n",
       " 'large': 339,\n",
       " 'hours': 340,\n",
       " 'eating': 341,\n",
       " 'blurry': 342,\n",
       " 'rider': 343,\n",
       " 'zooms': 344,\n",
       " 'past': 345,\n",
       " 'new': 346,\n",
       " 'mercedes': 347,\n",
       " 'skiers': 348,\n",
       " 'peak': 349,\n",
       " 'thee': 350,\n",
       " 'cats': 351,\n",
       " 'sleeping': 352,\n",
       " 'featuring': 353,\n",
       " 'everything': 354,\n",
       " 'lies': 355,\n",
       " 'smaller': 356,\n",
       " 'ball': 357,\n",
       " 'board': 358,\n",
       " 'playing': 359,\n",
       " 'frisbee': 360,\n",
       " 'washing': 361,\n",
       " 'dishes': 362,\n",
       " 'backpack': 363,\n",
       " 'holding': 364,\n",
       " 'arm': 365,\n",
       " 'shoulders': 366,\n",
       " 'girl': 367,\n",
       " 'next': 368,\n",
       " 'him': 369,\n",
       " 'three': 370,\n",
       " 'owners': 371,\n",
       " 'using': 372,\n",
       " 'go': 373,\n",
       " 'baby': 374,\n",
       " 'dog': 375,\n",
       " 'clock': 376,\n",
       " 'blends': 377,\n",
       " 'hangs': 378,\n",
       " 'multiple': 379,\n",
       " 'photos': 380,\n",
       " 'extends': 381,\n",
       " 'hand': 382,\n",
       " 'catch': 383,\n",
       " 'silverware': 384,\n",
       " 'glasses': 385,\n",
       " 'bottle': 386,\n",
       " 'wine': 387,\n",
       " 'vegetable': 388,\n",
       " 'age': 389,\n",
       " 'equipment': 390,\n",
       " 'kite': 391,\n",
       " 'shape': 392,\n",
       " 'bottom': 393,\n",
       " 'half': 394,\n",
       " 'fashioned': 395,\n",
       " 'ware': 396,\n",
       " 'middle': 397,\n",
       " 'croquet': 398,\n",
       " 'painted': 399,\n",
       " 'does': 400,\n",
       " 'trick': 401,\n",
       " 'surfboard': 402,\n",
       " 'under': 403,\n",
       " 'bunch': 404,\n",
       " 'strapped': 405,\n",
       " 'six': 406,\n",
       " 'time': 407,\n",
       " 'riders': 408,\n",
       " 'goes': 409,\n",
       " 'shot': 410,\n",
       " 'laundry': 411,\n",
       " 'bear': 412,\n",
       " 's': 413,\n",
       " 'other': 414,\n",
       " 'places': 415,\n",
       " 'friend': 416,\n",
       " 'seagull': 417,\n",
       " 'perches': 418,\n",
       " 'van': 419,\n",
       " 'parachutes': 420,\n",
       " 'fly': 421,\n",
       " 'through': 422,\n",
       " 'girls': 423,\n",
       " 'lunch': 424,\n",
       " 'stocked': 425,\n",
       " 'supplies': 426,\n",
       " 'dish': 427,\n",
       " 'chef': 428,\n",
       " 'opens': 429,\n",
       " 'beside': 430,\n",
       " 'island': 431,\n",
       " 'random': 432,\n",
       " 'tranport': 433,\n",
       " 'being': 434,\n",
       " 'prepared': 435,\n",
       " 'get': 436,\n",
       " 'newly': 437,\n",
       " 'family': 438,\n",
       " 'dirty': 439,\n",
       " 'clothes': 440,\n",
       " 'over': 441,\n",
       " 'edge': 442,\n",
       " 'body': 443,\n",
       " 'sun': 444,\n",
       " 'sets': 445,\n",
       " 'windows': 446,\n",
       " 'poses': 447,\n",
       " 'hill': 448,\n",
       " 'demonstrating': 449,\n",
       " 'act': 450,\n",
       " 'shelves': 451,\n",
       " 'wood': 452,\n",
       " 'assorted': 453,\n",
       " 'decorations': 454,\n",
       " 'plastic': 455,\n",
       " 'tarp': 456,\n",
       " 'courtyard': 457,\n",
       " 'reaches': 458,\n",
       " 'wave': 459,\n",
       " 'men': 460,\n",
       " 'seems': 461,\n",
       " 'others': 462,\n",
       " 'stairs': 463,\n",
       " 'lead': 464,\n",
       " 'double': 465,\n",
       " 'into': 466,\n",
       " 'footed': 467,\n",
       " 'tub': 468,\n",
       " 'bush': 469,\n",
       " 'bumper': 470,\n",
       " 'sticker': 471,\n",
       " 'word': 472,\n",
       " 'buffet': 473,\n",
       " 'different': 474,\n",
       " 'types': 475,\n",
       " 'organized': 476,\n",
       " 'closet': 477,\n",
       " 'female': 478,\n",
       " 'student': 479,\n",
       " 'bowls': 480,\n",
       " 'microwave': 481,\n",
       " 'storefronts': 482,\n",
       " 'right': 483,\n",
       " 'platform': 484,\n",
       " 'silhouette': 485,\n",
       " 'sunset': 486,\n",
       " 'tent': 487,\n",
       " 'stationed': 488,\n",
       " 'lane': 489,\n",
       " 'bath': 490,\n",
       " 'rug': 491,\n",
       " 'pile': 492,\n",
       " 'bikes': 493,\n",
       " 'rack': 494,\n",
       " 'outside': 495,\n",
       " 'stools': 496,\n",
       " 'takes': 497,\n",
       " 'selfie': 498,\n",
       " 'wrapped': 499,\n",
       " 'chain': 500,\n",
       " 'evergreen': 501,\n",
       " 'sprig': 502,\n",
       " 'grazes': 503,\n",
       " 'trees': 504,\n",
       " 'dogs': 505,\n",
       " 'beneath': 506,\n",
       " 'owner': 507,\n",
       " 'pristine': 508,\n",
       " 'waiting': 509,\n",
       " 'used': 510,\n",
       " 'smiles': 511,\n",
       " 'who': 512,\n",
       " 'wearing': 513,\n",
       " 'sarong': 514,\n",
       " 'together': 515,\n",
       " 'enjoying': 516,\n",
       " 'company': 517,\n",
       " 'crowd': 518,\n",
       " 'prepare': 519,\n",
       " 'ski': 520,\n",
       " 'snow': 521,\n",
       " 'slopes': 522,\n",
       " 'karaoke': 523,\n",
       " 'video': 524,\n",
       " 'skiiers': 525,\n",
       " 'gathered': 526,\n",
       " 'base': 527,\n",
       " 'travel': 528,\n",
       " 'guy': 529,\n",
       " 'building': 530,\n",
       " 'trusts': 531,\n",
       " 'another': 532,\n",
       " 'shave': 533,\n",
       " 'back': 534,\n",
       " 'neatly': 535,\n",
       " 'stacked': 536,\n",
       " 'shelf': 537,\n",
       " 'played': 538,\n",
       " 'yard': 539,\n",
       " 'copper': 540,\n",
       " 'pot': 541,\n",
       " 'racks': 542,\n",
       " 'stove': 543,\n",
       " 'restaurant': 544,\n",
       " 'filled': 545,\n",
       " 'folds': 546,\n",
       " 'watches': 547,\n",
       " 'boys': 548,\n",
       " 'play': 549,\n",
       " 'singing': 550,\n",
       " 'hikers': 551,\n",
       " 'climb': 552,\n",
       " 'snow-covered': 553,\n",
       " 'winter': 554,\n",
       " 'clutter': 555,\n",
       " 'blocks': 556,\n",
       " 'antique': 557,\n",
       " 'leaving': 558,\n",
       " 'reflection': 559,\n",
       " 'guys': 560,\n",
       " 'kid': 561,\n",
       " 'spa': 562,\n",
       " 'like': 563,\n",
       " 'shown': 564,\n",
       " 'only': 565,\n",
       " 'scissors': 566,\n",
       " 'loaded': 567,\n",
       " 'end': 568,\n",
       " 'orange': 569,\n",
       " 'gray': 570,\n",
       " 'accents': 571,\n",
       " 'free-standing': 572,\n",
       " 'door': 573,\n",
       " 'behind': 574,\n",
       " 'corner': 575,\n",
       " 'bricks': 576,\n",
       " 'lining': 577,\n",
       " 'teddy': 578,\n",
       " 'dimly': 579,\n",
       " 'lying': 580,\n",
       " 'bedspread': 581,\n",
       " 'mattress': 582,\n",
       " 'ocean': 583,\n",
       " 'loving': 584,\n",
       " 'pose': 585,\n",
       " 'fruit-adorned': 586,\n",
       " 'cake': 587,\n",
       " 'biker': 588,\n",
       " 'stands': 589,\n",
       " 'legs': 590,\n",
       " 'stone': 591,\n",
       " 'focus': 592,\n",
       " 'shirtless': 593,\n",
       " 'pink': 594,\n",
       " 'drinking': 595,\n",
       " 'dark': 596,\n",
       " 'profile': 597,\n",
       " 'before': 598,\n",
       " 'tops': 599,\n",
       " 'individual': 600,\n",
       " 'covers': 601,\n",
       " 'himself': 602,\n",
       " 'rainy': 603,\n",
       " 'day': 604,\n",
       " 'cleaning': 605,\n",
       " 'products': 606,\n",
       " 'four': 607,\n",
       " 'lawn': 608,\n",
       " 'females': 609,\n",
       " 'counter-topped': 610,\n",
       " 'ready': 611,\n",
       " 'skate': 612,\n",
       " 'cement': 613,\n",
       " 'seating': 614,\n",
       " 'basket': 615,\n",
       " 'yellow': 616,\n",
       " 'keyboard': 617,\n",
       " 'having': 618,\n",
       " 'slice': 619,\n",
       " 'bread': 620,\n",
       " 'jelly': 621,\n",
       " 'crossing': 622,\n",
       " 'placed': 623,\n",
       " 'passenger': 624,\n",
       " 'same': 625,\n",
       " 'chairs': 626,\n",
       " 'cupboards': 627,\n",
       " 'sandy': 628,\n",
       " 'mid': 629,\n",
       " 'sized': 630,\n",
       " 'leaning': 631,\n",
       " 'forward': 632,\n",
       " 'equipped': 633,\n",
       " 'support': 634,\n",
       " 'bars': 635,\n",
       " 'disabled': 636,\n",
       " 'television': 637,\n",
       " 'reflected': 638,\n",
       " 'off': 639,\n",
       " 'nap': 640,\n",
       " 'lays': 641,\n",
       " 'chest': 642,\n",
       " 'attached': 643,\n",
       " 'version': 644,\n",
       " 'personal': 645,\n",
       " 'dual': 646,\n",
       " 'wrap': 647,\n",
       " 'shadow': 648,\n",
       " 'un': 649,\n",
       " 'occupied': 650,\n",
       " 'allover': 651,\n",
       " 'tiling': 652,\n",
       " 'wig': 653,\n",
       " 'shopping': 654,\n",
       " 'center': 655,\n",
       " 'containing': 656,\n",
       " 'step': 657,\n",
       " 'close': 658,\n",
       " 'curtain': 659,\n",
       " 'cradled': 660,\n",
       " 'he': 661,\n",
       " 'falls': 662,\n",
       " 'asleep': 663,\n",
       " 'flat': 664,\n",
       " 'screen': 665,\n",
       " 'box': 666,\n",
       " 'tissues': 667,\n",
       " 'remote': 668,\n",
       " 'control': 669,\n",
       " 'nearly': 670,\n",
       " 'pets': 671,\n",
       " 'college': 672,\n",
       " 'campus': 673,\n",
       " 'splash': 674,\n",
       " 'added': 675,\n",
       " 'cleaned': 676,\n",
       " 'decluttered': 677,\n",
       " 'air': 678,\n",
       " 'just': 679,\n",
       " 'construction': 680,\n",
       " 'mirrir': 681,\n",
       " 'strip': 682,\n",
       " 'single': 683,\n",
       " 'teenage': 684,\n",
       " 'wire': 685,\n",
       " 'against': 686,\n",
       " 'surrounded': 687,\n",
       " 'handrails': 688,\n",
       " 'cards': 689,\n",
       " 'parade': 690,\n",
       " 'win': 691,\n",
       " 'industrial': 692,\n",
       " 'ovens': 693,\n",
       " 'pictured': 694,\n",
       " 'bowl': 695,\n",
       " 'separate': 696,\n",
       " 'showing': 697,\n",
       " 'inspecting': 698,\n",
       " 'project': 699,\n",
       " 'banquet': 700,\n",
       " 'tables': 701,\n",
       " 'held': 702,\n",
       " 'variety': 703,\n",
       " 'meats': 704,\n",
       " 'dips': 705,\n",
       " 'pastries': 706,\n",
       " 'plaza': 707,\n",
       " 'stores': 708,\n",
       " 'sedan': 709,\n",
       " 'cloudy': 710,\n",
       " 'microphones': 711,\n",
       " 'ages': 712,\n",
       " 'skiing': 713,\n",
       " 'slope': 714,\n",
       " 'gathering': 715,\n",
       " 'lighted': 716,\n",
       " 'something': 717,\n",
       " 'groceries': 718,\n",
       " 'race': 719,\n",
       " 'busy': 720,\n",
       " 'athletes': 721,\n",
       " 'appear': 722,\n",
       " 'disagreement': 723,\n",
       " 'lots': 724,\n",
       " 'space': 725,\n",
       " 'spiral': 726,\n",
       " 'hanging': 727,\n",
       " 'chihuahua': 728,\n",
       " 'attractive': 729,\n",
       " 'couch': 730,\n",
       " 'looks': 731,\n",
       " 'them': 732,\n",
       " 'older': 733,\n",
       " 'getting': 734,\n",
       " 'lookers': 735,\n",
       " 'refridgerator': 736,\n",
       " 'friends': 737,\n",
       " 'enjoy': 738,\n",
       " 'grassy': 739,\n",
       " 'fenced': 740,\n",
       " 'hooked': 741,\n",
       " 'checking': 742,\n",
       " 'holds': 743,\n",
       " 'leash': 744,\n",
       " 'fridge': 745,\n",
       " 'halfway': 746,\n",
       " 'during': 747,\n",
       " 'old-fashioned': 748,\n",
       " 'biking': 749,\n",
       " 'storefront': 750,\n",
       " 'sister': 751,\n",
       " 'trying': 752,\n",
       " 'high': 753,\n",
       " 'items': 754,\n",
       " 'shopper': 755,\n",
       " 'downtown': 756,\n",
       " 'mall': 757,\n",
       " 'kids': 758,\n",
       " 'moms': 759,\n",
       " 'master': 760,\n",
       " 'bedroom': 761,\n",
       " 'oddly': 762,\n",
       " 'shaped': 763,\n",
       " 'wires': 764,\n",
       " 'poles': 765,\n",
       " 'hall': 766,\n",
       " 'opening': 767,\n",
       " 'rooms': 768,\n",
       " 'nicely': 769,\n",
       " 'metallic': 770,\n",
       " 'skateboard': 771,\n",
       " 'doing': 772,\n",
       " 'communal': 773,\n",
       " 'technology': 774,\n",
       " 'spread': 775,\n",
       " 'cocker': 776,\n",
       " 'spaniel': 777,\n",
       " 'leans': 778,\n",
       " 'subway': 779,\n",
       " 'court': 780,\n",
       " 'below': 781,\n",
       " 'flowers': 782,\n",
       " 'srfer': 783,\n",
       " 'precariously': 784,\n",
       " 'hits': 785,\n",
       " 'big': 786,\n",
       " 'spending': 787,\n",
       " 'watching': 788,\n",
       " 'park': 789,\n",
       " 'flowering': 790,\n",
       " 'tree': 791,\n",
       " 'nearby': 792,\n",
       " 'were': 793,\n",
       " 'captured': 794,\n",
       " 'altered': 795,\n",
       " 'serving': 796,\n",
       " 'quiet': 797,\n",
       " 'adults': 798,\n",
       " 'meal': 799,\n",
       " 'hallway': 800,\n",
       " 'shirt': 801,\n",
       " 'jeans': 802,\n",
       " 'use': 803,\n",
       " 'professional': 804,\n",
       " 'laptop': 805,\n",
       " 'sage': 806,\n",
       " 'or': 807,\n",
       " 'kind': 808,\n",
       " 'spice': 809,\n",
       " 'crosswalk': 810,\n",
       " 'bags': 811,\n",
       " 'hands': 812,\n",
       " 'spacious': 813,\n",
       " 'tallk': 814,\n",
       " 'cross': 815,\n",
       " 'intersection': 816,\n",
       " 'skateboarding': 817,\n",
       " 'fushia': 818,\n",
       " 'cooking': 819,\n",
       " 'paneled': 820,\n",
       " 'reflecting': 821,\n",
       " 'opposite': 822,\n",
       " 'lcd': 823,\n",
       " 'panel': 824,\n",
       " 'numeric': 825,\n",
       " 'pad': 826,\n",
       " 'pretty': 827,\n",
       " 'spotless': 828,\n",
       " 'bidet': 829,\n",
       " 'beautiful': 830,\n",
       " 'blonde': 831,\n",
       " 'multicolored': 832,\n",
       " 'kiosk': 833,\n",
       " 'cyclists': 834,\n",
       " 'asphalt': 835,\n",
       " 'porcelain': 836,\n",
       " 'hexagonal': 837,\n",
       " 'waking': 838,\n",
       " 'coat': 839,\n",
       " 'wireless': 840,\n",
       " 'compatible': 841,\n",
       " 'role': 842,\n",
       " 'games': 843,\n",
       " 'hat': 844,\n",
       " 'traveling': 845,\n",
       " 'plate': 846,\n",
       " 'armor': 847,\n",
       " 'helmet': 848,\n",
       " 'reflective': 849,\n",
       " 'marble': 850,\n",
       " 'rust': 851,\n",
       " 'filthy': 852,\n",
       " 'alley': 853,\n",
       " 'hard': 854,\n",
       " 'waits': 855,\n",
       " 'frilly': 856,\n",
       " 'ramp': 857,\n",
       " 'asian': 858,\n",
       " 'lounge': 859,\n",
       " 'baskets': 860,\n",
       " 'goods': 861,\n",
       " 'floors': 862,\n",
       " 'gentleman': 863,\n",
       " 'alongside': 864,\n",
       " 'steele': 865,\n",
       " 'storage': 866,\n",
       " 'skateboarder': 867,\n",
       " 'airborne': 868,\n",
       " 'banana': 869,\n",
       " 'if': 870,\n",
       " 'telephone': 871,\n",
       " 'receiver': 872,\n",
       " 'bicyclists': 873,\n",
       " 'underneath': 874,\n",
       " 'drying': 875,\n",
       " 'modified': 876,\n",
       " 'read': 877,\n",
       " 'dress': 878,\n",
       " 'brushing': 879,\n",
       " 'teeth': 880,\n",
       " 'highly': 881,\n",
       " 'displaying': 882,\n",
       " 'train': 883,\n",
       " 'station': 884,\n",
       " 'made': 885,\n",
       " 'living': 886,\n",
       " 'daylit': 887,\n",
       " 'toothbrush': 888,\n",
       " 'leading': 889,\n",
       " 'where': 890,\n",
       " 'tires': 891,\n",
       " 'examines': 892,\n",
       " 'surfers': 893,\n",
       " 'ride': 894,\n",
       " 'ferry': 895,\n",
       " 'vespas': 896,\n",
       " 'books': 897,\n",
       " 'chair': 898,\n",
       " 'store': 899,\n",
       " 'doll': 900,\n",
       " 'cup': 901,\n",
       " 'coffee': 902,\n",
       " 'brushes': 903,\n",
       " 'bikers': 904,\n",
       " 'turn': 905,\n",
       " 'fountain': 906,\n",
       " 'town': 907,\n",
       " 'bicyclist': 908,\n",
       " 'wait': 909,\n",
       " 'shines': 910,\n",
       " 'keys': 911,\n",
       " 'lettering': 912,\n",
       " 'competing': 913,\n",
       " 'handicap': 914,\n",
       " 'bar': 915,\n",
       " 'natural': 916,\n",
       " 'fronted': 917,\n",
       " 'combo': 918,\n",
       " 'peleton': 919,\n",
       " 'passing': 920,\n",
       " 'long': 921,\n",
       " 'staring': 922,\n",
       " 'facing': 923,\n",
       " 'knight': 924,\n",
       " 'costume': 925,\n",
       " 'motorcycle': 926,\n",
       " 'driving': 927,\n",
       " 'skate-board': 928,\n",
       " 'stack': 929,\n",
       " 'beverages': 930,\n",
       " 'standup': 931,\n",
       " 'male': 932,\n",
       " 'dump': 933,\n",
       " 'truck': 934,\n",
       " 'commercial': 935,\n",
       " 'mirrors': 936,\n",
       " 'toothbrushes': 937,\n",
       " 'pole': 938,\n",
       " 'power': 939,\n",
       " 'lines': 940,\n",
       " 'seats': 941,\n",
       " 'blow': 942,\n",
       " 'candle': 943,\n",
       " 'birthday': 944,\n",
       " 'besides': 945,\n",
       " 'soccer': 946,\n",
       " 'fan': 947,\n",
       " 'dressing': 948,\n",
       " 'japanese': 949,\n",
       " 'displayed': 950,\n",
       " 'married': 951,\n",
       " 'posing': 952,\n",
       " 'piece': 953,\n",
       " 'performing': 954,\n",
       " 'passes': 955,\n",
       " 'shinning': 956,\n",
       " 'bright': 957,\n",
       " 'entryway': 958,\n",
       " 'tricks': 959,\n",
       " 'tan': 960,\n",
       " 'jacuzzi': 961,\n",
       " 'sweater': 962,\n",
       " 'inspired': 963,\n",
       " 'alone': 964,\n",
       " 'mirorror': 965,\n",
       " 'locked': 966,\n",
       " 'meter': 967,\n",
       " 'catches': 968,\n",
       " 'but': 969,\n",
       " 'fall': 970,\n",
       " 'stopped': 971,\n",
       " 'downed': 972,\n",
       " 'drink': 973,\n",
       " 'outfit': 974,\n",
       " 'cutout': 975,\n",
       " 'sheer': 976,\n",
       " 'curtains': 977,\n",
       " 'warrior': 978,\n",
       " 'skiis': 979,\n",
       " 'tissue': 980,\n",
       " 'dispenser': 981,\n",
       " 'panelling': 982,\n",
       " 'unused': 983,\n",
       " 'topsand': 984,\n",
       " 'cabinettes': 985,\n",
       " '2': 986,\n",
       " 'ceramic': 987,\n",
       " 'dinner': 988,\n",
       " 'tiny': 989,\n",
       " 'little': 990,\n",
       " 'reaching': 991,\n",
       " 'drawer': 992,\n",
       " 'arranged': 993,\n",
       " 'display': 994,\n",
       " 'decoratively': 995,\n",
       " 'resting': 996,\n",
       " 'matching': 997,\n",
       " 'bathing': 998,\n",
       " 'hot': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(vocab, \"vocab_v2.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "def collate_fn(batch):\n",
    "    images, captions = zip(*batch)\n",
    "    tokens = [torch.tensor([vocab[token] for token in caption])\n",
    "              for caption in captions]\n",
    "    lengths = [len(caption) for caption in captions]\n",
    "    captions = pad_sequence(tokens, batch_first=True)\n",
    "    # lengths = captions.shape[-2]\n",
    "    # captions = pack_padded_sequence(input=captions, batch_first=True, lengths=lengths, enforce_sorted=False)\n",
    "    return torch.stack(images), captions, lengths\n",
    "    \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 384, 384]) tensor([[   0,   12, 1538,   38,  258,   12,   31, 3108,   19,  701,    5,    2,\n",
      "          617,    0,    0],\n",
      "        [   0,  339, 5553,  578,  412,  330,   38,  258,   12,   31,  301,   12,\n",
      "            2,  899,    0],\n",
      "        [   0, 1053,  170,   78,    2,  443,   12,  279,   19, 2499,    0,    0,\n",
      "            0,    0,    0],\n",
      "        [   0,  169,  128,  927,   31,  174,  267,   12,   50,    0,    0,    0,\n",
      "            0,    0,    0]]) [13, 15, 11, 9]\n"
     ]
    }
   ],
   "source": [
    "for images, captions, lens in train_dataloader:\n",
    "    print(images.shape, captions, lens)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VisionEncoder(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.model = efficientnet_v2_s(weights=weights)\n",
    "        self.model.classifier = nn.Sequential(nn.Linear(1280, embedding_size))\n",
    "        self.batch_norm = nn.BatchNorm1d(embedding_size, momentum=0.01)\n",
    "    \n",
    "    def forward(self, input_images):\n",
    "        with torch.no_grad():\n",
    "            features = self.model(input_images)\n",
    "            features = self.batch_norm(features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VisionEncoder(768)(torch.randn(4, 3, 384, 384)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21162832"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in VisionEncoder(768).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDecoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, vocabulary_size, num_layers, max_seq_len=20):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear_layer = nn.Linear(hidden_size, vocabulary_size)\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def forward(self, input_features, capts, lens):\n",
    "        embeddings = self.embedding(capts)\n",
    "        features = torch.cat([input_features.unsqueeze(1), embeddings], dim=1)\n",
    "        features = pack_padded_sequence(features, lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _ = self.rnn(features)\n",
    "        return self.linear_layer(hidden[0])\n",
    "    \n",
    "    def sample(self, input_features, lstm_states):\n",
    "        sampled_indices = []\n",
    "        lstm_inputs = input_features.unsqueeze(1)\n",
    "        for i in range(self.max_seq_len):\n",
    "            hidden_variables, lstm_states = self.lstm_layer(lstm_inputs, lstm_states)          # hiddens: (batch_size, 1, hidden_size)\n",
    "            model_outputs = self.linear_layer(hidden_variables.squeeze(1))            # outputs:  (batch_size, vocab_size)\n",
    "            _, predicted_outputs = model_outputs.max(1)                        # predicted: (batch_size)\n",
    "            sampled_indices.append(predicted_outputs)\n",
    "            lstm_inputs = self.embedding_layer(predicted_outputs)                       # inputs: (batch_size, embed_size)\n",
    "            lstm_inputs = lstm_inputs.unsqueeze(1)                         # inputs: (batch_size, 1, embed_size)\n",
    "        sampled_indices = torch.stack(sampled_indices, 1)                # sampled_ids: (batch_size, max_seq_length)\n",
    "        return sampled_indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 29645])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "for image, captions, lens in train_dataloader:\n",
    "    print(TextDecoder(768, 512, len(vocab.word2idx), 1)(torch.randn((4, 768)), captions, lens).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "encoder_model = VisionEncoder(256).to(device)\n",
    "decoder_model = TextDecoder(256, 512, len(vocab.word2idx), 1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "parameters = list(decoder_model.parameters()) + \\\n",
    "    list(encoder_model.model.classifier.parameters()) + \\\n",
    "    list(encoder_model.batch_norm.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5], Step [0/103529], Loss: 10.3047, Perplexity: 29874.0555\n",
      "Epoch [0/5], Step [10/103529], Loss: 9.5898, Perplexity: 14614.5124\n",
      "Epoch [0/5], Step [20/103529], Loss: 6.7709, Perplexity: 872.0854\n",
      "Epoch [0/5], Step [30/103529], Loss: 6.0673, Perplexity: 431.5164\n",
      "Epoch [0/5], Step [40/103529], Loss: 6.4110, Perplexity: 608.4881\n",
      "Epoch [0/5], Step [50/103529], Loss: 6.7764, Perplexity: 876.9159\n",
      "Epoch [0/5], Step [60/103529], Loss: 6.0911, Perplexity: 441.9282\n",
      "Epoch [0/5], Step [70/103529], Loss: 6.3808, Perplexity: 590.3780\n",
      "Epoch [0/5], Step [80/103529], Loss: 5.5497, Perplexity: 257.1693\n",
      "Epoch [0/5], Step [90/103529], Loss: 6.0465, Perplexity: 422.6142\n",
      "Epoch [0/5], Step [100/103529], Loss: 5.5821, Perplexity: 265.6391\n",
      "Epoch [0/5], Step [110/103529], Loss: 5.7238, Perplexity: 306.0673\n",
      "Epoch [0/5], Step [120/103529], Loss: 5.9305, Perplexity: 376.3278\n",
      "Epoch [0/5], Step [130/103529], Loss: 6.4169, Perplexity: 612.0779\n",
      "Epoch [0/5], Step [140/103529], Loss: 6.5135, Perplexity: 674.2010\n",
      "Epoch [0/5], Step [150/103529], Loss: 5.2216, Perplexity: 185.2391\n",
      "Epoch [0/5], Step [160/103529], Loss: 5.5296, Perplexity: 252.0317\n",
      "Epoch [0/5], Step [170/103529], Loss: 5.6287, Perplexity: 278.2990\n",
      "Epoch [0/5], Step [180/103529], Loss: 4.7217, Perplexity: 112.3619\n",
      "Epoch [0/5], Step [190/103529], Loss: 5.0451, Perplexity: 155.2532\n",
      "Epoch [0/5], Step [200/103529], Loss: 5.1318, Perplexity: 169.3217\n",
      "Epoch [0/5], Step [210/103529], Loss: 4.0689, Perplexity: 58.4903\n",
      "Epoch [0/5], Step [220/103529], Loss: 5.0310, Perplexity: 153.0891\n",
      "Epoch [0/5], Step [230/103529], Loss: 5.3259, Perplexity: 205.5927\n",
      "Epoch [0/5], Step [240/103529], Loss: 4.6224, Perplexity: 101.7416\n",
      "Epoch [0/5], Step [250/103529], Loss: 4.6602, Perplexity: 105.6610\n",
      "Epoch [0/5], Step [260/103529], Loss: 5.6042, Perplexity: 271.5692\n",
      "Epoch [0/5], Step [270/103529], Loss: 3.9310, Perplexity: 50.9579\n",
      "Epoch [0/5], Step [280/103529], Loss: 5.0340, Perplexity: 153.5414\n",
      "Epoch [0/5], Step [290/103529], Loss: 4.3781, Perplexity: 79.6880\n",
      "Epoch [0/5], Step [300/103529], Loss: 5.0901, Perplexity: 162.4130\n",
      "Epoch [0/5], Step [310/103529], Loss: 4.9672, Perplexity: 143.6185\n",
      "Epoch [0/5], Step [320/103529], Loss: 4.6548, Perplexity: 105.0906\n",
      "Epoch [0/5], Step [330/103529], Loss: 5.0518, Perplexity: 156.3021\n",
      "Epoch [0/5], Step [340/103529], Loss: 4.6026, Perplexity: 99.7404\n",
      "Epoch [0/5], Step [350/103529], Loss: 4.3190, Perplexity: 75.1116\n",
      "Epoch [0/5], Step [360/103529], Loss: 4.4363, Perplexity: 84.4596\n",
      "Epoch [0/5], Step [370/103529], Loss: 3.7810, Perplexity: 43.8582\n",
      "Epoch [0/5], Step [380/103529], Loss: 3.9866, Perplexity: 53.8734\n",
      "Epoch [0/5], Step [390/103529], Loss: 5.0262, Perplexity: 152.3504\n",
      "Epoch [0/5], Step [400/103529], Loss: 5.6408, Perplexity: 281.6967\n",
      "Epoch [0/5], Step [410/103529], Loss: 4.6160, Perplexity: 101.0887\n",
      "Epoch [0/5], Step [420/103529], Loss: 5.3390, Perplexity: 208.3097\n",
      "Epoch [0/5], Step [430/103529], Loss: 5.3647, Perplexity: 213.7313\n",
      "Epoch [0/5], Step [440/103529], Loss: 5.3517, Perplexity: 210.9587\n",
      "Epoch [0/5], Step [450/103529], Loss: 4.3931, Perplexity: 80.8871\n",
      "Epoch [0/5], Step [460/103529], Loss: 3.5021, Perplexity: 33.1863\n",
      "Epoch [0/5], Step [470/103529], Loss: 4.6250, Perplexity: 101.9978\n",
      "Epoch [0/5], Step [480/103529], Loss: 3.7841, Perplexity: 43.9944\n",
      "Epoch [0/5], Step [490/103529], Loss: 4.8227, Perplexity: 124.3025\n",
      "Epoch [0/5], Step [500/103529], Loss: 3.9880, Perplexity: 53.9465\n",
      "Epoch [0/5], Step [510/103529], Loss: 3.0720, Perplexity: 21.5851\n",
      "Epoch [0/5], Step [520/103529], Loss: 3.7853, Perplexity: 44.0493\n",
      "Epoch [0/5], Step [530/103529], Loss: 4.0134, Perplexity: 55.3374\n",
      "Epoch [0/5], Step [540/103529], Loss: 5.1574, Perplexity: 173.7135\n",
      "Epoch [0/5], Step [550/103529], Loss: 3.8794, Perplexity: 48.3946\n",
      "Epoch [0/5], Step [560/103529], Loss: 5.8929, Perplexity: 362.4436\n",
      "Epoch [0/5], Step [570/103529], Loss: 4.4881, Perplexity: 88.9509\n",
      "Epoch [0/5], Step [580/103529], Loss: 4.9986, Perplexity: 148.2123\n",
      "Epoch [0/5], Step [590/103529], Loss: 4.7919, Perplexity: 120.5256\n",
      "Epoch [0/5], Step [600/103529], Loss: 4.6270, Perplexity: 102.2080\n",
      "Epoch [0/5], Step [610/103529], Loss: 4.9927, Perplexity: 147.3315\n",
      "Epoch [0/5], Step [620/103529], Loss: 4.6037, Perplexity: 99.8573\n",
      "Epoch [0/5], Step [630/103529], Loss: 3.4348, Perplexity: 31.0243\n",
      "Epoch [0/5], Step [640/103529], Loss: 4.3246, Perplexity: 75.5350\n",
      "Epoch [0/5], Step [650/103529], Loss: 3.6912, Perplexity: 40.0936\n",
      "Epoch [0/5], Step [660/103529], Loss: 5.8676, Perplexity: 353.4160\n",
      "Epoch [0/5], Step [670/103529], Loss: 5.3807, Perplexity: 217.1758\n",
      "Epoch [0/5], Step [680/103529], Loss: 3.7534, Perplexity: 42.6640\n",
      "Epoch [0/5], Step [690/103529], Loss: 4.8515, Perplexity: 127.9380\n",
      "Epoch [0/5], Step [700/103529], Loss: 3.8654, Perplexity: 47.7227\n",
      "Epoch [0/5], Step [710/103529], Loss: 4.8071, Perplexity: 122.3734\n",
      "Epoch [0/5], Step [720/103529], Loss: 3.9065, Perplexity: 49.7269\n",
      "Epoch [0/5], Step [730/103529], Loss: 5.3470, Perplexity: 209.9684\n",
      "Epoch [0/5], Step [740/103529], Loss: 5.2689, Perplexity: 194.1940\n",
      "Epoch [0/5], Step [750/103529], Loss: 3.1281, Perplexity: 22.8294\n",
      "Epoch [0/5], Step [760/103529], Loss: 4.0819, Perplexity: 59.2569\n",
      "Epoch [0/5], Step [770/103529], Loss: 5.1562, Perplexity: 173.5114\n",
      "Epoch [0/5], Step [780/103529], Loss: 4.7455, Perplexity: 115.0648\n",
      "Epoch [0/5], Step [790/103529], Loss: 4.4745, Perplexity: 87.7488\n",
      "Epoch [0/5], Step [800/103529], Loss: 4.0066, Perplexity: 54.9600\n",
      "Epoch [0/5], Step [810/103529], Loss: 4.7098, Perplexity: 111.0355\n",
      "Epoch [0/5], Step [820/103529], Loss: 3.4558, Perplexity: 31.6833\n",
      "Epoch [0/5], Step [830/103529], Loss: 3.7703, Perplexity: 43.3934\n",
      "Epoch [0/5], Step [840/103529], Loss: 2.8219, Perplexity: 16.8094\n",
      "Epoch [0/5], Step [850/103529], Loss: 3.6518, Perplexity: 38.5422\n",
      "Epoch [0/5], Step [860/103529], Loss: 3.6952, Perplexity: 40.2529\n",
      "Epoch [0/5], Step [870/103529], Loss: 5.9180, Perplexity: 371.6589\n",
      "Epoch [0/5], Step [880/103529], Loss: 4.3653, Perplexity: 78.6745\n",
      "Epoch [0/5], Step [890/103529], Loss: 2.0985, Perplexity: 8.1542\n",
      "Epoch [0/5], Step [900/103529], Loss: 4.2937, Perplexity: 73.2390\n",
      "Epoch [0/5], Step [910/103529], Loss: 4.1577, Perplexity: 63.9224\n",
      "Epoch [0/5], Step [920/103529], Loss: 3.2256, Perplexity: 25.1675\n",
      "Epoch [0/5], Step [930/103529], Loss: 5.0367, Perplexity: 153.9673\n",
      "Epoch [0/5], Step [940/103529], Loss: 4.3826, Perplexity: 80.0472\n",
      "Epoch [0/5], Step [950/103529], Loss: 3.3861, Perplexity: 29.5492\n",
      "Epoch [0/5], Step [960/103529], Loss: 4.4199, Perplexity: 83.0877\n",
      "Epoch [0/5], Step [970/103529], Loss: 3.1740, Perplexity: 23.9038\n",
      "Epoch [0/5], Step [980/103529], Loss: 5.0120, Perplexity: 150.2080\n",
      "Epoch [0/5], Step [990/103529], Loss: 3.5256, Perplexity: 33.9752\n"
     ]
    }
   ],
   "source": [
    "total_num_steps = len(train_dataloader)\n",
    "import numpy as np\n",
    "\n",
    "for epoch in range(1):\n",
    "    for i, (imgs, capts, lens) in enumerate(train_dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        capts = capts.to(device)\n",
    "        tgts = pack_padded_sequence(capts, lens, batch_first=True, enforce_sorted=False)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        feats = encoder_model(imgs)\n",
    "        output = decoder_model(feats, capts, lens)\n",
    "\n",
    "        loss = criterion(output, tgts.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}'\n",
    "                  .format(epoch, 5, i, total_num_steps, loss.item(), np.exp(loss.item()))) \n",
    " \n",
    "        # Save the model checkpoints\n",
    "        if (i+1) % 1000 == 0:\n",
    "            torch.save(decoder_model.state_dict(), os.path.join(\n",
    "                'models_dir/', 'decoder-{}-{}.pt'.format(epoch+1, i+1)))\n",
    "            torch.save(encoder_model.state_dict(), os.path.join(\n",
    "                'models_dir/', 'encoder-{}-{}.pt'.format(epoch+1, i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
